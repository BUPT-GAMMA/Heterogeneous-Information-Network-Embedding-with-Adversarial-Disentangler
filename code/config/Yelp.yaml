exp_setting:
  exp_name: 'Yelp'                         # Expriment title, log/checkpoint files will be named after this
  checkpoint_dir: './checkpoint/'          # Folder for model checkpoints
  log_dir: './log/'                        # Folder for training logs
  data_root: '../datasets/'
  seed: 9
  n_nodes: 2614
  input_dim: 256
  mp_1: 'UBU'
  mp_2: 'UBSBU'
  mp_3: 'UBRBU'


model:
  vae:
    encoder: [['fc', 64, 'bn', 'LeakyReLU', 0.5],
              ['fc', 64, 'bn', 'LeakyReLU', 0.5]
             ]
    decoder: [['fc', 128, '', 'LeakyReLU', 0.5,  True],
              ['fc', 256, '', 'LeakyReLU', 0.5, False]
             ]
    lr: 0.0015
    betas: [0.5, 0.999]

  D_mp:
    dnn: [['fc', 32, '', 'LeakyReLU', 0.5],
          ['fc', 3, '', 'LeakyReLU', 0.5]
         ]
    lr: 0.001
    betas: [0.5,0.999]

  D:
    dnn: [['fc', 32, '', 'LeakyReLU', 0.5],
          ['fc', [1,3], '', 'LeakyReLU', 0.5]
         ]
    lr: 0.001
    betas: [0.5,0.999]


trainer:
  total_step: 20000
  batch_size: 32

  lambda:
    reconstruct:
      init: 100
      final: 1
      step: 10000
    kl:
      init: 0.0001
      final: 0.0001
      step: 1
    adv_mp_clf:
      init: 0
      final: 1
      step: 10
    gp:
      init: 300
      final: 300
      step: 1
    d_adv:
      init: 0
      final: 0.002
      step: 100
    d_clf:
      init: 0
      final: 0.002
      step: 100

  verbose_step: 15
  save_log: True
  save_checkpoint: True
  save_best_only: True
