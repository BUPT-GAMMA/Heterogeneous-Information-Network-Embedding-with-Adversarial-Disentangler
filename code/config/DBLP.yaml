exp_setting:
  exp_name: 'DBLP'                         # Expriment title, log/checkpoint files will be named after this
  checkpoint_dir: './checkpoint/'          # Folder for model checkpoints
  log_dir: './log/'                        # Folder for training logs
  data_root: '../datasets/'
  seed: 9
  n_nodes: 14475
  input_dim: 256
  mp_1: 'APA'
  mp_2: 'APTPA'
  mp_3: 'APCPA'
  mp_4: 'PAP'
  mp_5: 'PTP'
  mp_6: 'PCP'


model:
  vae:
    encoder: [['fc', 128, 'bn', 'LeakyReLU', 0.2],
              ['fc', 64, '', 'LeakyReLU', 0.2]
             ]
    decoder: [['fc', 128, 'bn', 'LeakyReLU', 0.2, True],
              ['fc', 256, '', 'LeakyReLU', 0.2, False]
             ]
    lr: 0.001
    betas: [0.5,0.999]

  D_mp:
    dnn: [['fc', 32, '', 'LeakyReLU', 0.2],
          ['fc', 3, 'bn', 'LeakyReLU', 0.2]
         ]
    lr: 0.001
    betas: [0.5,0.999]

  D:
    dnn: [['fc', 128, '', 'LeakyReLU', 0.2],
          ['fc', [1,3], '', 'LeakyReLU', 0.2]
         ]
    lr: 0.001
    betas: [0.5,0.999]


trainer:
  total_step: 40000
  batch_size: 32

  lambda:
    reconstruct:
      init:  100
      final: 1
      step:  10000
    kl:
      init:  0.015
      final: 0.015
      step:  1
    adv_mp_clf:
      init:  0
      final: 1
      step: 10
    gp:
      init: 450
      final: 450
      step: 1
    d_adv:
      init: 0
      final: 0.002
      step: 100
    d_clf:
      init: 0
      final: 0.002
      step: 100

  verbose_step: 80
  save_log: True
  save_checkpoint: True
  save_best_only: True
